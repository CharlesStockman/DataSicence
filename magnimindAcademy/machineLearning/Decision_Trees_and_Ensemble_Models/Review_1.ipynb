{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08278860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exam 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424f9035",
   "metadata": {},
   "source": [
    "<b>Question : If highly correlated but relevant features are present \n",
    "in a dataset, Lasso regression will select one of them at random</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb862e6",
   "metadata": {},
   "source": [
    "Answer : F -- The Lasso model regularizes model parameters by shrinking the regression coefficients and reducing some of them to 0.\n",
    "Every non zero values is selected to be uxed in the model so it is not random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3030705a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T18:47:07.661648Z",
     "start_time": "2023-05-05T18:47:07.643952Z"
    }
   },
   "source": [
    "<b>Question: Tuning two hyper-parameters with four options each using grid-search \n",
    "with 5-fold cross-validation requires exactly 40 model fits.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7306966c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T18:48:03.620675Z",
     "start_time": "2023-05-05T18:48:03.616764Z"
    }
   },
   "source": [
    "Answer True -- 2 hyperparameters * 5 fold * 4 options for each hyperparameter</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdf8c9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T18:50:11.743056Z",
     "start_time": "2023-05-05T18:50:11.738963Z"
    }
   },
   "source": [
    "<b>Question: It is good practice to standardize sparse datasets \n",
    "so that each feature has zero mean.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f527b8",
   "metadata": {},
   "source": [
    "Answer False -- Standardization assume you data has a Gaussian distribution.  If the distribution is not known normalization would be better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a280c",
   "metadata": {},
   "source": [
    "<b>Question: Kernel support vector machines don’t scale well to large datasets.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5191efe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T19:15:37.500228Z",
     "start_time": "2023-05-05T19:15:37.495461Z"
    }
   },
   "source": [
    "Answer True -- Training time is high when we have large data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ae3fb",
   "metadata": {},
   "source": [
    "<b>Question: Ridge Regression adds an L1-norm penalty to the cost function and often sets several of the weights to zero</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ddd765",
   "metadata": {},
   "source": [
    "Answer : Set a feature to 0 is same as getting rid of the feature.  A characteristic of Ridge Regression is that it keeps all the \n",
    "features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51839783",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T19:34:38.475012Z",
     "start_time": "2023-05-05T19:34:38.470672Z"
    }
   },
   "source": [
    "<b>Question: Using kernel trick, one can get non-linear decision boundaries using algorithms designed originally for linear models.\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d764105",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T19:53:54.832051Z",
     "start_time": "2023-05-05T19:53:54.829371Z"
    }
   },
   "outputs": [],
   "source": [
    "Answer : True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e8b3c",
   "metadata": {},
   "source": [
    "<b>Question: 5-NN has more overfitting (lower bias) than 1-NN.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c9803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T19:49:57.953542Z",
     "start_time": "2023-05-05T19:49:57.949241Z"
    }
   },
   "source": [
    "Answer False : K-NN is the number of points that will have their distances calculated from the selected piont.  For a small number of nearest neighbor points then the point will be more sensitve to local anomalies in weight.   The decison will be made by one small area of the graph insttead of the global characteristics of the graph.\n",
    "\n",
    "Note : Too many point and the local strcuture will be loss.  Too few points and the points will overfit the in their small region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12729d3c",
   "metadata": {},
   "source": [
    "<b>Question: It is important that exactly same scaling transformation is applied to the training set and the test set for the supervised model.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d1d88f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-05T20:15:04.146624Z",
     "start_time": "2023-05-05T20:15:04.143119Z"
    }
   },
   "outputs": [],
   "source": [
    "Answer: True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f389f02b",
   "metadata": {},
   "source": [
    "<b>Question: Despite its name, LogisticRegression is a classification algorithm and not a regression algorithm.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97a06a",
   "metadata": {},
   "source": [
    "Answer True: Does classification and is used when the dependent variable is categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca23109",
   "metadata": {},
   "source": [
    "<b> Question: The distinction between the training set, validation set, and test set is funda- mentally important to apply machine learning methods in practice. Any choices made based on the test set accuracy “leak” information from the test set into the model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808c1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer : That is why the test is used infrequenty ( only when the \n",
    "                                                    data is being set\n",
    "                                                   to QA or production)\n",
    "The data is seen very rerely so the conclusions \n",
    "drawn from it do not have much effect on the training \n",
    "dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5cdfcf",
   "metadata": {},
   "source": [
    "11. (4 points) After training a ridge regression model, you find the training and test accuracies are 0.97 and 0.55, respectively. Which of the following would be the best choice for the next ridge regression model you train?\n",
    "\n",
    "A. You are overfitting, the next model trained should have a lower value for alpha<br>\n",
    "B. You are overfitting, the next model trained should have a higher value for alpha<br>\n",
    "C. You are underfitting, the next model trained should have a lower value for alpha<br>\n",
    "D. You are underfitting, the next model trained should have a higher value for alpha<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51324f",
   "metadata": {},
   "source": [
    "Answer :C -- C is the hyperparameter controlling how much to avoid misclassifying the point.  For large values of C the smaller no man's land is smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34411114",
   "metadata": {},
   "source": [
    "(4 points) Which of the following variables should be treated as categorical? 􏰀 Income\n",
    "􏰀 Nationality 􏰀 Gender\n",
    "􏰀 Age\n",
    "􏰀 ZIP code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac08c2a",
   "metadata": {},
   "source": [
    "Answer All But Income -- A categorical varible is a countable number of distinct groups.  Also a string is piece of data such as cat, dog\n",
    "that can be anything where a categorical value is a defned group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "<b>Question: Suppose you are interested in finding a parsimonious model (the model that\n",
    "accomplishes the desired level of prediction with as few predictor variables as possible)\n",
    "to predict housing prices. Which of the following would be the best choice?\n",
    "A. Ridge Regression\n",
    "B. Ordinary Least Squares Regression\n",
    "C. Logistic Regression\n",
    "D. Lasso Regression</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2efdd0",
   "metadata": {},
   "source": [
    "Answer D: It was covered in Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182cbda4",
   "metadata": {},
   "source": [
    "<b>Question:  Which of the following is not part of data preprocessing?\n",
    "A. Scaling\n",
    "B. Data transformation\n",
    "C. One-Hot-Encoding\n",
    "D. Feature Selection\n",
    "E. Cross-validation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb54f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d88bd2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T14:48:37.659105Z",
     "start_time": "2023-05-06T14:48:37.622990Z"
    }
   },
   "source": [
    "<b>Question: (10 points) Task: Perform grid search (without using the GridSearchCV class) using a\n",
    "split into training, validation, and test data, with a final valuation on the test data.\n",
    "    \n",
    "`X_trainval, X_test, y_trainval, y_test=train_test_split(X,y)\n",
    "train_test_split(X_trainval, y_trainval)\n",
    "best_score=0\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    svm=LinearSVC(C=C)\n",
    "    svm.fit(X_train, y_train)\n",
    "    score=svm.score(X_test, y_test)\n",
    "if score > best_score:\n",
    "    best_score=score\n",
    "    best_C=C`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c56c7b0",
   "metadata": {},
   "source": [
    "Answer:\n",
    "1. X_train, X_valid, y_train, y_valid=\n",
    "The X_valid and y_train should be switched\n",
    "\n",
    "class dataset \n",
    "    list x\n",
    "    list y\n",
    "\n",
    "Psuedo code<br>\n",
    "    Concat the Test and Validation into 2 list X,y call X, y<br>\n",
    "    Get the nums of rows called row_count<br>\n",
    "    Using List Comprehension split the X,y into x_lists, y_lists<br>\n",
    "    Create a data object and each min_x_lists to x, min_y_lists to y<br>\n",
    "    for validation_set in dataset:<br>\n",
    "        X_train = data.x drop validation_set  # Create training set<br>\n",
    "        y_train = data.y drop validation_set  # Create training set<br>\n",
    "        X_valid = data.x[validation_set]<br>\n",
    "        y_valid = data.y[validation_set]<br>\n",
    "        \n",
    "        # call the code mentioned above<br>\n",
    "     \n",
    "      svm=LinearSVC(C=best_C).fit(X_valid, y_valid)<br>\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27500e13",
   "metadata": {},
   "source": [
    "*** Do this one after the course has ended since we never covered it\n",
    "7. (10 points) Task: Use the PowerTransformer (implementing the box-cos transformation) transformer to preprocesss data and learn a Ridge model.\n",
    "pipe=make_pipeline (StandardScaler(), PowerTransformer(), Ridge())\n",
    "scores=cross_val_score(pipe, X_train, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85289693",
   "metadata": {},
   "source": [
    "Give X and numpy and y as numpy\n",
    "Provide code to build LogisticRegression model and evaluate its performance on a separate test set, given a dataset as numpy arrays X and y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed0f73",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression<br>\n",
    "(X_train, X_test, y_train, y_test) = tain_test_split()<br>\n",
    "logistic_regression = LogisticRegression()<br>\n",
    "logistic_regression.fit(X_train, y_train)<br>\n",
    "logistic_regression.score(X_test, y_test)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf3b5a",
   "metadata": {},
   "source": [
    "<b>Question: (10 points) Provide code to implement grid-searching the parameters C and gamma of anSVC in a pipeline with a StandardScaler, and evaluating the best parameter settingon a separate test set, given a dataset as numpy arrays X and y.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d304f4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T17:39:54.703428Z",
     "start_time": "2023-05-07T17:39:54.662109Z"
    }
   },
   "source": [
    "# Answer\n",
    "'''from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'C': [.1,1,10,100,100],\n",
    "        'gamma': [1,.1,.01,.001,.0001]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(SVC(), parameters, verbose=3)\n",
    "grid.fit(Xtrain,yTrain)\n",
    "\n",
    "best_estimator = grid.best_estimator_<br>\n",
    "yBestPredict = best_estimator.fit(Xtest,ytest)<br>\n",
    "print(classification_report(yTrain, yBestPredict))<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a06718",
   "metadata": {},
   "source": [
    "<b>Question: What is overfitting ? </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc536ed",
   "metadata": {},
   "source": [
    "Overfitting happens when the machine learning algorihtm remembers the \n",
    "training dataset exactly including the noise.  Also, it does not \n",
    "perform well on the test data \n",
    "\n",
    "This could happen for a number of reasons: \n",
    "> * model is to complex\n",
    "> * The data has not been clean which leads to too much noise\n",
    "> * The model is too complex\n",
    "\n",
    "Way to fix\n",
    "> * GridSearchCV\n",
    "> * Using Lasso Regression ( Decreasing the features )\n",
    "> * Cleaning the data\n",
    "> * Increasing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c204a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T17:43:57.063986Z",
     "start_time": "2023-05-07T17:43:56.990136Z"
    }
   },
   "source": [
    "<b>Question:Why are nearest neighbor methods sensitive to the scaling of the data<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b47b0d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T17:50:49.842996Z",
     "start_time": "2023-05-07T17:50:49.822926Z"
    }
   },
   "source": [
    "Answer: The problem with features (columns) is\n",
    "each column has it own range.  If the ranges are \n",
    "vastly different one range could dominate over \n",
    "the others.  This is a form of bias.  By scaling \n",
    "all the varaibles are using the same scale so \n",
    "there is no scaling bias to the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d2566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
