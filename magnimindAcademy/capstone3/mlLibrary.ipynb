{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f32dedf8-1e3e-49f2-b2bf-1a4fb96a2111",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrives fucntions to detailed information about the data\n",
    "%run BasicDataExploration.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24c0509-571f-41ce-830d-48009238249f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialCleanup(dataframe):\n",
    "    '''\n",
    "        Some Basic Cleanup including:\n",
    "            Removing the spaces from columns\n",
    "            Converting the datatypes that are object to strings\n",
    "            lowercae all character and remove space on the left and right side of the text\n",
    "    '''\n",
    "    dataframe = cleanColumnHeaders(dataframe)\n",
    "    dataframe = fixColumnTypes(dataframe)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62929565-d6a0-47ce-9a1d-fd647184744b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createDataframesForModel(dataframe, column_list):\n",
    "    '''\n",
    "        From an inital dataframe create mulitple dataframes for gender ( male and female)\n",
    "    '''\n",
    "    df_revision = dataframe[column_list].copy(deep=True)\n",
    "    df_revision.Gender = df_revision.Gender.str.strip().str.lower()\n",
    "    df_female = df_revision[ df_revision['Gender'] == 'f']\n",
    "    df_male   = df_revision[ df_revision['Gender'] == 'm' ]\n",
    "    return (df_female, df_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ac9810-d9a0-4f16-9c93-8e69be2d8f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createTestTrainData(dataframe, test_size):\n",
    "    '''\n",
    "        Create the Train/Test dataset for one dataframe\n",
    "        Stratify is being used to avoid inbalancing dataset\n",
    "        \n",
    "        Inputs: \n",
    "            dataFrame -- A dataframe with features and target\n",
    "            test_size -- The size ( 0 < x <= 1)\n",
    "        Output \n",
    "            The XTrain and yTrain, the YTrain and YTest\n",
    "    '''\n",
    "    (XTrain, XTest, yTrain, yTest) = train_test_split(\n",
    "        dataframe.drop('SARCOPENIA', axis=1), \n",
    "        dataframe['SARCOPENIA'], \n",
    "        test_size=test_size, \n",
    "        train_size=1-test_size)\n",
    "       \n",
    "    return (XTrain, XTest, yTrain, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36c7fad0-4ffd-4b90-b840-6c315a9771a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def showBalanceOfDataset(columns,*targetSeries):\n",
    "    '''\n",
    "        Creates a side effect of plotting the of rows haveing disease/not having disease\n",
    "        \n",
    "        Inputs:\n",
    "            columns -- A title for eaach dataset\n",
    "            targetSeries -- The collection of the datasets.  One for each item in the column list\n",
    "            \n",
    "        Output:\n",
    "            None\n",
    "    '''\n",
    "    figure = plt.figure(figsize=(10,5))\n",
    "\n",
    "    columns = [\"Train Male\", \"Test Male\", \"Train Female\", \"Test Female\"] \n",
    "    X_axis = np.arange(len(columns))\n",
    "    \n",
    "    disease_yes = []\n",
    "    disease_no = []\n",
    "    for series in targetSeries:\n",
    "        raw_data = series.groupby(series).count()\n",
    "        disease_no.append(raw_data[0])\n",
    "        disease_yes.append(raw_data[1])\n",
    "    \n",
    "    plt.bar(X_axis - 0.2, disease_no, 0.4, label = 'No Disease')\n",
    "    plt.bar(X_axis + 0.2, disease_yes,0.4, label = 'Disease')\n",
    "    plt.xticks(X_axis, columns)\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.xlabel(\"Data Set\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fa30c1-e483-4c61-9a6f-3bc5bcabd7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanDataSet(dataframe):\n",
    "    column_list = dataframe.select_dtypes(include='string[python]').columns\n",
    "    for column in column_list:\n",
    "        dataframe[column] = dataframe[column].str.strip().str.lower()\n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5d63264-6ea7-4dce-8c9b-dd53e93271a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanEducation(dataframe, field):\n",
    "    '''\n",
    "        Changes the data in the columns to make it easier to convert to categorical data\n",
    "        \n",
    "        input\n",
    "            dataframe -- The frame with the education field\n",
    "            field -- The name of the education field\n",
    "            \n",
    "        output \n",
    "            A dataframe with a cleaned Education Field\n",
    "    '''\n",
    "    # Constants -- The condensed set of strings\n",
    "    illerate=\"illiterate\"\n",
    "    university=\"university\"\n",
    "    high_school=\"high_school\"\n",
    "    junior_high=\"junior_high\"\n",
    "    elementry=\"elementry\"\n",
    "\n",
    "    # Convert the data in the columns to easilty convert to categorical data \n",
    "    translation_education = {}\n",
    "    translation_education[\"illiterate\"] = illerate\n",
    "    translation_education[\"illeterate\"] = illerate\n",
    "    translation_education[\"i̇lliterate\"] = illerate\n",
    "    translation_education[\"ılliterate\"] = illerate\n",
    "    translation_education[\"okur-yzar değil\"] = illerate\n",
    "    translation_education[\"university\"] = university\n",
    "    translation_education[\"üniversite\"] = university\n",
    "    translation_education[\"high school\"] = high_school\n",
    "    translation_education[\"secondary school\"] = high_school\n",
    "    translation_education[\"high_school\"] = high_school\n",
    "    translation_education[\"highschool\"] = high_school\n",
    "    translation_education[\"lise\"] = high_school\n",
    "    translation_education[\"primary_school\"] = elementry\n",
    "    translation_education[\"ilkokul\"] = elementry\n",
    "    translation_education[\"middle school\"] = junior_high\n",
    "    translation_education[\"junior high\"] = junior_high\n",
    "    translation_education[\"junior_high\"] = junior_high\n",
    "    translation_education[\"ortaokul\"] = junior_high\n",
    "\n",
    "                      \n",
    "    def fix(value):\n",
    "        if pd.isnull(value):\n",
    "            return value\n",
    "        else:             \n",
    "            new_value = translation_education.get(value)\n",
    "            if new_value == None: \n",
    "                new_value = value\n",
    "        return new_value\n",
    "                      \n",
    "    dataframe[field] = dataframe[field].apply(fix)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66f31646-1222-49e9-aad1-83065f7383c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createGraph(rows,cols):\n",
    "    (figure, axis) = plt.subplots(rows,cols, figsize=(15,5))\n",
    "    reval_ax = np.ravel(axis)\n",
    "    return figure,reval_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "403f017f-97d1-4296-b18b-9c0b3d1baca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createHeatMap(dataframe, index):\n",
    "    numerical_dataframe = df_male.select_dtypes(include=np.number)\n",
    "    correlation = numerical_dataframe.corr()\n",
    "    sns.heatmap(correlation, mask=np.triu(correlation), annot=True, ax=ax[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "956312c4-a419-4c56-ab1a-353bef585a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestScore(pipeLine, parameters, cv,train,test):\n",
    "    '''\n",
    "        Run the pipleline and generated the prdection for the features\n",
    "\n",
    "            pipeline -- The preprocessing and machine learning algoirthm used in the experiment\n",
    "            cv       -- Number running for each different permuation of the parameters\n",
    "            train    -- The features and target of the training set\n",
    "            test     -- The features and target of the test dataset\n",
    "\n",
    "        Output\n",
    "            The pipline used in the test and array of predictions computer from feature test set.\n",
    "    '''\n",
    "    grid_pipeline = GridSearchCV(pipeline, param_grid=parameters, cv=cv, return_train_score=True, verbose=3, error_score='raise')\n",
    "    grid_pipeline.fit(train[0], train[1])\n",
    "    print(test[0].shape)\n",
    "    y_predictions = grid_pipeline.predict(test[0])\n",
    "    grid_pipeline.score(test[0], test[1])\n",
    "\n",
    "    return grid_pipeline, y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f477694-982a-49e8-b57d-35f92f566d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def feature(grid):\n",
    "        '''\n",
    "            Create a bar graph shown the effect the features have on the target\n",
    "\n",
    "            Input:\n",
    "                grid -- The Grid containng the model, feature names\n",
    "            Output:\n",
    "                Noen\n",
    "            Side3 Effect \n",
    "                Display a graph showing a bar graph of how the featrues affect the target\n",
    "        '''\n",
    "        \n",
    "        machine_learning_model = grid.best_estimator_.steps[1][1]\n",
    "        coefficients = machine_learning_model.coef_[0].squeeze()\n",
    "        names = grid.best_estimator_.named_steps[\"Column Transformers\"].get_feature_names_out()\n",
    "\n",
    "        features = pd.DataFrame(columns=[\"labels\", \"values\"])\n",
    "        features[\"labels\"] = names\n",
    "        features[\"values\"] = coefficients\n",
    "        features.plot.barh(x=\"labels\", y=\"values\", legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8473dd6d-16ac-4a5e-a11e-674cbcae6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def results(grid, step_name, x, y, y_prediction, results_dataframe,filename):\n",
    "    '''\n",
    "        For each experiment displays the basic scores, accuracy and the confusion matrixes\n",
    "\n",
    "        Accuracy -- Number of correct preidictions( True Positive + True Negative ) / Total Number of prediction \n",
    "        Precison -- True Positive / True Positive + False Positive\n",
    "        Recall   -- True Positive / True Positive + False Negative -- Proportion of actual positives was indentified correctly\n",
    "        F1 -- Relies on both precision and recall so it represents both in one metric\n",
    "            F1 = 2 / (1/recall) + (1/precison) == ( 2 * precision * recall) / ( precision + recall ) ==\n",
    "\n",
    "            ( 2 * True Positive ) / ( 2 * True positive + False Positive + False Negative )\n",
    "\n",
    "        Note : Usually improving Precision harms Recall and improving recall harms Precision\n",
    "\n",
    "        Roc Curve -- The performance of a classification thresholds with two parameters : True Postive , Fals Positive Rate\n",
    "\n",
    "            TPR = True Positive / ( True Positive )\n",
    "            FPR = False Positive / ( False Positive + True Negative )\n",
    "            Lowering the classification threshold classifies more items item as postiive thus increasing the False Positive, True Postive\n",
    "\n",
    "        AUC is the Area under the Roc Curve which is the measure of performance across all possible classification thresholds\n",
    "        \n",
    "\n",
    "        input:\n",
    "            grid -- The preprocessing and machine learning algoirthm used in the experiment\n",
    "            step_name -- The name of the step that does the machine learning algorithm\n",
    "            x -- The dataset contianing the testing features\n",
    "            y -- The dataset containing the target\n",
    "            y -- The dataset of targets generated by compuing the target value from the independent values\n",
    "            results_dataframe -- The dataframe where the resules are stored so we can use them in futre runs.  \n",
    "                In order to get of invaldi run delete them from file\n",
    "            filename -- The fileanme for the storage of results_dataframe\n",
    "    '''\n",
    "    def auc(y, y_prediction):\n",
    "        '''\n",
    "            Calcuate area under an ROC Curve\n",
    "\n",
    "            Inputs:\n",
    "                y -- The dataset containing the target\n",
    "                y -- The dataset of targets generated by compuing the target value from the independent values\n",
    "\n",
    "            Output \n",
    "                Area Under the ROC Curve\n",
    "        '''\n",
    "        false_positive_rates, true_positive_rate, thresholds = roc_curve(y, y_prediction,pos_label=2)\n",
    "        return auc(false_positive_rates, true_positive_rate)\n",
    "\n",
    "    training_score = np.round(grid.cv_results_['mean_train_score'][0],2)\n",
    "    test_score = np.round(grid.cv_results_['mean_test_score'][0],2)\n",
    "    accuracy =  np.round(accuracy_score(y_true = y, y_pred = y_prediction),2)\n",
    "    precision = np.round(precision_score(y, y_pred=y_prediction, zero_division=1),2)\n",
    "    recall = np.round(recall_score(y, y_pred=y_prediction),2)\n",
    "    \n",
    "    print(\"The Training Score is \", training_score)\n",
    "    print(\"The Test     Score is \", test_score)\n",
    "    print(\"Accuracy     Score is \", accuracy)\n",
    "    print(\"Precision    Score is \", precision)\n",
    "    print(\"Recall       Score is \", recall)\n",
    "    print(\"best               is \", grid.best_params_)\n",
    "    \n",
    "    dataframe = addResultsToDataFrame(results_dataframe, \n",
    "                                grid.best_params_,\n",
    "                                training_score,\n",
    "                                test_score,\n",
    "                                accuracy,\n",
    "                                precision,\n",
    "                                recall, \n",
    "                                filename)\n",
    "                            \n",
    "    text_confusion_matrix = confusion_matrix(y, y_pred=y_prediction)\n",
    "    display = ConfusionMatrixDisplay(confusion_matrix=text_confusion_matrix, display_labels=['Disease', 'No Disease', ])\n",
    "    display.plot()\n",
    "    \n",
    "    RocCurveDisplay.from_predictions(y, y_pred=y_prediction)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1fc16b5-ed67-419d-83f2-f5139157f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def feature_random_forest(grid):\n",
    "        '''\n",
    "            Create a bar graph shown the effect the features have on the target for random forest\n",
    "\n",
    "            Input:\n",
    "                grid -- The Grid containng the model, feature names.  This will be a random forest\n",
    "            Output:\n",
    "                Noen\n",
    "            Side3 Effect \n",
    "                Display a graph showing a bar graph of how the featrues affect the target\n",
    "        '''\n",
    "\n",
    "        machine_learning_model = grid.best_estimator_.steps[1][1]\n",
    "        print(\"model = \", type(machine_learning_model))\n",
    "        coefficients = machine_learning_model.feature_importances_.squeeze()\n",
    "        names = grid.best_estimator_.named_steps[\"Column Transformers\"].get_feature_names_out()\n",
    "\n",
    "        features = pd.DataFrame(columns=[\"labels\", \"values\"])\n",
    "        features[\"labels\"] = names\n",
    "        features[\"values\"] = coefficients\n",
    "        features.plot.barh(x=\"labels\", y=\"values\", legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "224b0b75-af4b-48ad-bc2b-8be052613d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResultsDataFrame(filename):\n",
    "    '''\n",
    "        Purpose get the dataframe to add run to\n",
    "\n",
    "        input: \n",
    "            filename -- Name of file\n",
    "        output \n",
    "            if ( new is true ) then a new dataframe else dataframe\n",
    "    ''' \n",
    "    try:\n",
    "        dataframe = pd.read_csv(filename)\n",
    "        data_frame = pd.read_csv(filename)\n",
    "    except FileNotFoundError:\n",
    "        columns = [\"Best Parameters\", \"Training Score\", \"Testing Score\", \"Accuracy\", \"Precision\", \"Recall\"]\n",
    "        dataframe = pd.DataFrame(columns=columns)\n",
    "\n",
    "    return dataframe\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9892df1c-2b1d-423a-aef7-a8c649027239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addResultsToDataFrame(df, bestParameters, trainingScore, testScore, accuracy, precision, recall, filename):\n",
    "    '''\n",
    "        Adds a row to the dataframe and save to a file \n",
    "\n",
    "        Input:\n",
    "            df -- The dataframe to append the data\n",
    "            bestparameters -- The bestParmameters for that current run\n",
    "            trainingSocre -- The socre of the trainging data\n",
    "            testScore -- The score of the test data\n",
    "            accuracy -- Number of True Positives vs False Postivies \n",
    "            precision -- Number of Correct Conditions vs false positives\n",
    "            recall -- Proportion of actual positives was indentified correctly\n",
    "    '''\n",
    "    data = [ bestParameters, trainingScore, testScore, accuracy, precision, recall ]\n",
    "    df.loc[ len(df) ] = data\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe0f5de8-ea40-411d-9800-0fb4315ffd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFrame(filename):\n",
    "    return pd.read_csv(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
